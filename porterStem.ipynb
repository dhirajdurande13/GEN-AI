{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steaming:-is process of reducing a word to it's word steam that affixes to suffixes and prefixes and or the root of the word known as lema\n",
    "# example: eat eaten eating here eat is steam just one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['eat','eaten','eating','programing','program','sentence']\n",
    "# porter streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat---->eat\n",
      "eaten---->eaten\n",
      "eating---->eat\n",
      "programing---->program\n",
      "program---->program\n",
      "sentence---->sentenc\n"
     ]
    }
   ],
   "source": [
    "stemming=PorterStemmer()\n",
    "for word in words:\n",
    "    print(word+\"---->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to stemming some of the words not get exact what we want for example : sentence converted sentenc\n",
    "# for fixing it we use limitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegexpStemer class: with the help of which we can eaisily implement reguler expression stemmer algorithm\n",
    "# take single reguler expression and remove suffix and preffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RegexpStemmer: 'ing$|s$|e$|able$'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regStem=RegexpStemmer(\"ing$|s$|e$|able$\",min=4) # it will remove at the last end only \n",
    "regStem\n",
    "# in the last word if ing s e or able it will try to remove it\n",
    "# if we put $ first it will remove first if we want to remove from both side then just remove doller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regStem.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnowBall Stemr : better than porter stemer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat---->eat\n",
      "eaten---->eaten\n",
      "eating---->eat\n",
      "programing---->program\n",
      "program---->program\n",
      "sentence---->sentenc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'port'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "#perform better than porterstem\n",
    "snStemin=SnowballStemmer('english')\n",
    "for word in words:\n",
    "    print(word+\"---->\"+snStemin.stem(word))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "snStemin.stem('portingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmetization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmetizer=WordNetLemmatizer()\n",
    "lemmetizer.lemmatize(\"going\",pos='v')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ddurande/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ddurande/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # Optional but recommended for better lemmatization support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat------->eat\n",
      "eaten------->eaten\n",
      "eating------->eating\n",
      "programing------->programing\n",
      "program------->program\n",
      "sentence------->sentence\n"
     ]
    }
   ],
   "source": [
    "words=['eat','eaten','eating','programing','program','sentence']\n",
    "\n",
    "for word in words:\n",
    "    print(word+'------->'+lemmetizer.lemmatize(word,pos='a'))\n",
    "\n",
    "\n",
    "    # here pos:-\n",
    "    # noun n\n",
    "    # verb v\n",
    "    # adverb r\n",
    "    # adjective a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
